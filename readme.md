# 微调LLM,BGE语料生成
## requirements

- 目前只需要安装openai 1.13.3一个库就能使用
- 需要GPT3.5turbo的API_KEY（大概两块一个可以自己去买）

## 已有功能及使用方法

### 1.从资料文本中提炼问答用于微调LLM

- 在make_dialogue.py中

核心思路就是给GPT一段文本，加上prompt后缀，让他根据这段资料自己构造三组对话。

- 第一步：input.txt中输入分段好的资料文本

- 第二步：utils/call_gpt.py中填入API_KEYS

- 第三步：main.py中修改如下字段以匹配你要的功能，滑动窗口即一次性传给GPT的段数。

  ```python
   # 设置角色
  now_role = '''你是一个专业的医疗助手'''
   # 设置prompt
  prompt_list = '''以上是一段医学相关的文本资料，请你根据上述资料的内容，给出针对文本中知识的三对问答，提问和回答请用换行分开，不要有多余输出'''
   # 设置滑动窗口的大小
  WINDOW_SIZE = 3
  ```

- 运行后存入qa_list.json

### 2.从资料中提炼真问题和假问题

- 在make_question.py中

提炼真问题假问题，用于微调BGE以适用垂直领域sentence embedding

- 对于每段文本，提出两个真问题，两个假问题，并且写入jsonl文件中，格式按照bge微调的要求。如下：
```
{"query": "相关文本", "pos": ["真问题1", "真问题2"], "neg": ["假问题1", "假问题2"]}
```
  
## 待完成功能

- 多线程询问
- 现在的prompt只是随便写出来尝试的，还有待优化

## 更新日志
- 2024.3.12 - 初步写了从文本资料中提炼对话的代码。
- 2024.3.13 - 更新滑动窗口的功能，避免连续几段讲同一个知识点导致不能同时传给GPT的情况。